{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Distraction Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Fa91cgXnVwPo",
    "outputId": "2395a9a8-301a-4677-97d8-ba02830b82ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (1.1.7)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tensorflow in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: transformers in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (4.34.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (2.14.6)\n",
      "Requirement already satisfied: torch in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: certifi==2022.12.7 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (2022.12.7)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: idna==2.10 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (1.26.1)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (10.1.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: supervision in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (0.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (2.0.7)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.25.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from datasets) (14.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: sympy in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from aiohttp->datasets) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from matplotlib->roboflow) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from matplotlib->roboflow) (4.43.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from matplotlib->roboflow) (6.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.41.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->roboflow) (3.17.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (6.8.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\magnico\\documents\\gitprojects\\driver_detection\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install roboflow tensorflow scikit-learn opencv-python transformers datasets torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Magnico\\Documents\\GitProjects\\driver_detection\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import base64\n",
    "import io\n",
    "import requests\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BeitImageProcessor, BeitForSemanticSegmentation\n",
    "from datasets import load_dataset\n",
    "from roboflow import Roboflow\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "DISTRACTION_CLASSES = {\n",
    "    0: \"Safe Driving\",\n",
    "    1: \"Texting\",\n",
    "    2: \"Talking on the phone\",\n",
    "    3: \"Operating the radio\",\n",
    "    4: \"Drinking\",\n",
    "    5: \"Reaching behind\",\n",
    "    6: \"Talking to passenger\",\n",
    "}\n",
    "\n",
    "with open('./file_label_map.pkl', 'rb') as f:\n",
    "        label_map = pickle.load(f)\n",
    "\n",
    "FOLDERS = ['./body/', './valid']\n",
    "for folder in FOLDERS:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_proyect(path):\n",
    "    model = path.split('/')[-1]\n",
    "\n",
    "    if model == 'base.pkl':\n",
    "        rf = Roboflow(api_key='mjAeKepHoqRRVOJpbG3W')\n",
    "        project = rf.workspace(\"new-workspace-vrhvx\").project(\"distracted-driver-detection\")\n",
    "        dataset = project.version(3).download(\"tfrecord\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_body(image, save = False, class_index = 12, save_path = './frames', filename = 'result.png'):\n",
    "    global body_model\n",
    "\n",
    "    # Preprocesamiento de la imagen\n",
    "    image = cv2.resize(image, (640, 640))\n",
    "\n",
    "    # Inferencia\n",
    "    inputs = body_model[0](images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # Inferencia\n",
    "    output = body_model[1](**inputs)\n",
    "    output = output.logits\n",
    "    \n",
    "    logits_s = output.squeeze(0)\n",
    "\n",
    "    # Apply softmax to convert logits to probabilities\n",
    "    probs = F.softmax(logits_s, dim=0)\n",
    "\n",
    "    # Create a binary mask for the desired class\n",
    "    binary_mask = (probs[class_index, :, :] > 0.5).float()\n",
    "\n",
    "    # Convert image to tensor\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    # Resize the binary mask to match the image dimensions\n",
    "    binary_mask_resized = F.interpolate(binary_mask.unsqueeze(0).unsqueeze(0), size=image_tensor.shape[2:], mode='nearest').squeeze(0).squeeze(0)\n",
    "\n",
    "    # Create a dark tensor (all zeros)\n",
    "    dark_tensor = torch.zeros_like(image_tensor)\n",
    "\n",
    "    # Set the pixels outside the mask to dark\n",
    "    dark_tensor[0, :, :] = dark_tensor[0, :, :] * (1 - binary_mask_resized)\n",
    "\n",
    "    # Combine the image and binary mask\n",
    "    combined_image = image_tensor * binary_mask_resized + dark_tensor\n",
    "\n",
    "    # Convert the combined tensor back to a PIL Image\n",
    "    img = transforms.ToPILImage()(combined_image.squeeze())\n",
    "    \n",
    "    if save:\n",
    "        img.save(os.path.join(save_path, filename))\n",
    "    img = np.array(img).reshape(-1, 640, 640, 3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_hugging_face(filename):\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/microsoft/beit-base-finetuned-ade-640-640\"\n",
    "    headers = {\"Authorization\": f\"Bearer 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\"}\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.post(API_URL, headers=headers, data=data)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def applyPersonMask(frame):\n",
    "    # Obtener respuesta de la API de Hugging Face\n",
    "    response = query_hugging_face(frame)\n",
    "    person_mask = [item['mask'] for item in response if item['label'] == 'person']\n",
    "    person_mask = person_mask[0] if person_mask else None\n",
    "\n",
    "    if not person_mask:\n",
    "        # Manejar el caso en el que no se detecta ninguna persona en la imagen\n",
    "        return None\n",
    "\n",
    "    # Decodificar la máscara base64 a bytes y leerla directamente en un array de NumPy\n",
    "    mask_data = base64.b64decode(person_mask)\n",
    "    mask_np_array = np.frombuffer(mask_data, dtype=np.uint8)\n",
    "    mask_image = cv2.imdecode(mask_np_array, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Cargar la imagen original\n",
    "    original_image = cv2.imread(frame)\n",
    "    \n",
    "    # Cambiar tamaño de la máscara para que coincida con el tamaño de la imagen original si es necesario\n",
    "    if original_image.shape[:2] != mask_image.shape[:2]:\n",
    "        mask_image = cv2.resize(mask_image, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "    # Crear una imagen con fondo negro\n",
    "    black_background_image = np.zeros_like(original_image)\n",
    "\n",
    "    # Asegurarse de que la máscara tiene un solo canal y es del mismo tamaño que la imagen\n",
    "    mask_image = mask_image.astype(float) / 255  # Normalizar la máscara a valores entre 0 y 1\n",
    "\n",
    "    # Usar la máscara para copiar los pixeles de la persona de la imagen original al fondo negro\n",
    "    for i in range(3):  # Solo para los canales RGB\n",
    "        black_background_image[:, :, i] = original_image[:, :, i] * mask_image\n",
    "\n",
    "    # Cambiar tamaño de la imagen final a (640, 640)\n",
    "    recortada_image_resized = cv2.resize(black_background_image, (640, 640))\n",
    "\n",
    "    img = Image.fromarray(recortada_image_resized)\n",
    "    \n",
    "    img = np.array(img).reshape(-1, 640, 640, 3)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_distraction(image, api=False):\n",
    "    global  base_model\n",
    "\n",
    "    #image = applyPersonMask(image) if api else detect_body(image)\n",
    "\n",
    "    return base_model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_data(path):\n",
    "    model = path.split('/')[-1]\n",
    "\n",
    "    if model == 'body.pkl':\n",
    "        return load_dataset(\"hf-internal-testing/fixtures_ade20k\", split=\"test\")\n",
    "\n",
    "    if model == 'base.pkl':\n",
    "        label_map = {}\n",
    "        with open(\"./Distracted-Driver-Detection-3/train/driver_label_map.pbtxt\", \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            for i in range(0, len(lines), 5):  # Asumiendo que cada item ocupa 5 líneas\n",
    "                label = lines[i + 1].split('\"')[1]\n",
    "                label_id = int(lines[i + 2].split(\":\")[1].split(\",\")[0].strip())\n",
    "                label_map[label_id] = label\n",
    "\n",
    "        # Leer driver.tfrecord\n",
    "        raw_image_dataset = tf.data.TFRecordDataset('./Distracted-Driver-Detection-3/train/driver.tfrecord')\n",
    "\n",
    "        # Definir las características que quieres extraer\n",
    "        image_feature_description = {\n",
    "            'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "            'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/filename': tf.io.VarLenFeature(tf.string)\n",
    "        }\n",
    "\n",
    "        def _parse_image_function(example_proto):\n",
    "            return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "        parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "        for image_features in parsed_image_dataset:\n",
    "            image_raw = image_features['image/encoded'].numpy()\n",
    "            label = image_features['image/object/class/label'].values.numpy()[0]\n",
    "\n",
    "            # Convertir la imagen en formato raw a una matriz de numpy\n",
    "            image = cv2.imdecode(np.asarray(bytearray(image_raw), dtype=\"uint8\"), cv2.IMREAD_COLOR)\n",
    "            \n",
    "            # use body_model for image segmentation segm\n",
    "\n",
    "            image = detect_body(image)\n",
    "\n",
    "            X.append(image)\n",
    "            y.append(label)\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Convertir etiquetas a números\n",
    "        categories_dict = {category: index for index, category in enumerate(set(y))}\n",
    "        y = np.array([categories_dict[label] for label in y])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "        return [X_train, X_test, y_train, y_test, categories_dict]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For performance purposes we will use the pre-procesed data\n",
    "def prepare_model_data(path):\n",
    "    model = path.split('/')[-1]\n",
    "\n",
    "    if model == 'body.pkl':\n",
    "        return load_dataset(\"hf-internal-testing/fixtures_ade20k\", split=\"test\")\n",
    "\n",
    "    if model == 'base.pkl':\n",
    "        files = os.listdir('./body')\n",
    "        with open('./file_label_map.pkl', 'rb') as f:\n",
    "            label_map = pickle.load(f)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        for file in files:\n",
    "            image = cv2.imread(os.path.join('./body', file))\n",
    "\n",
    "            X.append(image)\n",
    "            y.append(label_map[file])\n",
    "            \n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Convertir etiquetas a números\n",
    "        categories_dict = {category: index for index, category in enumerate(set(y))}\n",
    "        y = np.array([categories_dict[label] for label in y])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "        return [X_train, X_test, y_train, y_test, categories_dict]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(path, data):\n",
    "    modelo = path.split('/')[-1]\n",
    "    if modelo == 'body.pkl':\n",
    "        feature_extractor = BeitImageProcessor.from_pretrained(\n",
    "            'microsoft/beit-base-finetuned-ade-640-640')\n",
    "        body = BeitForSemanticSegmentation.from_pretrained(\n",
    "            'microsoft/beit-base-finetuned-ade-640-640')\n",
    "        return [feature_extractor, body]\n",
    "\n",
    "    if modelo == 'base.pkl':\n",
    "        [X_train, X_test, y_train, y_test, categories_dict] = data\n",
    "        base = None\n",
    "\n",
    "        # Asegurarse de que todas las imágenes tienen la misma forma\n",
    "        if all(i.shape == X_train[0].shape for i in X_train):\n",
    "\n",
    "            # Normalizar datos\n",
    "            X_train = X_train / 255.0\n",
    "            X_test = X_test / 255.0\n",
    "\n",
    "            # Modelo CNN\n",
    "            base = Sequential()\n",
    "\n",
    "            # Capa 1\n",
    "            base.add(Conv2D(30, (3, 3), input_shape=X_train.shape[1:]))\n",
    "            base.add(Activation('relu'))\n",
    "            base.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            base.add(Dropout(0.2))\n",
    "\n",
    "            # Capa 2\n",
    "            base.add(Conv2D(50, (3, 3), kernel_regularizer='l1'))\n",
    "            base.add(Activation('relu'))\n",
    "\n",
    "            # Capa 2\n",
    "            base.add(Conv2D(50, (3, 3), kernel_regularizer='l1'))\n",
    "            base.add(Activation('relu'))\n",
    "\n",
    "            # Capa 3\n",
    "            base.add(Flatten())\n",
    "            base.add(Dense(30))\n",
    "            base.add(Activation('relu'))\n",
    "\n",
    "            # Capa de salida\n",
    "            base.add(Dense(len(categories_dict)))\n",
    "            base.add(Activation('softmax'))\n",
    "\n",
    "            # Compilación del modelo\n",
    "            base.compile(\n",
    "                optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Entrenamiento\n",
    "            base.fit(X_train, y_train, epochs=6,\n",
    "                     validation_data=(X_test, y_test))\n",
    "\n",
    "        else:\n",
    "            print(\"No todas las imágenes tienen la misma forma. Asegúrate de preprocesarlas para que tengan la misma forma antes de alimentarlas al modelo.\")\n",
    "\n",
    "        return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "XVR7-etO7iuT"
   },
   "outputs": [],
   "source": [
    "def init_model(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as file:\n",
    "            modelo = pickle.load(file)\n",
    "            print(f\"Modelo {path} cargado correctamente.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No se encontró el archivo {path}.\")\n",
    "        print(\"Descargando proyecto...\")\n",
    "        proyect = download_proyect(path)\n",
    "\n",
    "        print(\"Preparando datos...\")\n",
    "        data = prepare_model_data(path)\n",
    "\n",
    "        print(\"Entrenando modelo...\")\n",
    "        modelo = train_model(path, data)\n",
    "\n",
    "        print(\"Guardando modelo...\")\n",
    "        with open(path, 'wb') as file:\n",
    "            pickle.dump(modelo, file)\n",
    "            print(\"Modelo guardado correctamente.\")\n",
    "    \n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    global body_model, base_model\n",
    "\n",
    "    body_model = init_model(\"./models/body.pkl\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    base_model = init_model(\"./models/base.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of statistical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states_statistics(path='./body'):\n",
    "    global valid_label_map\n",
    "    states = {}\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if DISTRACTION_CLASSES[valid_label_map[file]] in states:\n",
    "            states[DISTRACTION_CLASSES[valid_label_map[file]]] += 1\n",
    "        else:\n",
    "            states[DISTRACTION_CLASSES[valid_label_map[file]]] = 1\n",
    "\n",
    "    #Amount of images per class\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(range(len(states)), list(states.values()), align='center')\n",
    "    plt.xticks(range(len(states)), list(states.keys()))\n",
    "    plt.show()\n",
    "\n",
    "    #Percentage of images per class\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.pie(list(states.values()), labels=list(states.keys()), autopct='%1.1f%%')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_classification_report(api=False):\n",
    "    with open('./valid/valid_img_labels.pkl', 'rb') as f:\n",
    "        valid_label_map = pickle.load(f)\n",
    "    carpeta = \"./valid/all\"\n",
    "    predictions = {}\n",
    "    X = []\n",
    "    y = []\n",
    "    y_pred = []\n",
    "\n",
    "    for filename in os.listdir(carpeta):\n",
    "        print(filename)\n",
    "        if api:\n",
    "            pred = detect_distraction(os.path.join(carpeta, filename), api=True)\n",
    "        else:\n",
    "            img = cv2.imread(os.path.join(carpeta, filename))\n",
    "            img = cv2.resize(img, (640,640)) \n",
    "            img = np.array(img)\n",
    "            img = img.reshape(-1, 640, 640, 3)\n",
    "            pred = detect_distraction(img)\n",
    "\n",
    "        predictions[filename] = pred\n",
    "        y_pred.append(pred)\n",
    "        y.append(valid_label_map[filename])\n",
    "\n",
    "    y_pred_rs = [p[0] for p in y_pred]\n",
    "    y_pred_classes = np.argmax(y_pred_rs,axis=1)\n",
    "\n",
    "    # Generate and print classification report\n",
    "    print(classification_report(y, y_pred_classes, target_names=DISTRACTION_CLASSES.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo ./models/body.pkl cargado correctamente.\n",
      "\n",
      "Modelo ./models/base.pkl cargado correctamente.\n"
     ]
    }
   ],
   "source": [
    "load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "# Cargar el archivo pickle\n",
    "with open('./valid/valid_img_labels.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Iterar a través de las entradas y mover las imágenes a las carpetas correspondientes\n",
    "for image_name, category in data.items():  # Asumiendo que el pickle es un diccionario\n",
    "    # Crear una carpeta para la categoría si no existe\n",
    "    category_folder = os.path.join('./Data/original/val/', str(category))\n",
    "    if not os.path.exists(category_folder):\n",
    "        os.makedirs(category_folder)\n",
    "    \n",
    "    # Construir la ruta completa del archivo de destino\n",
    "    destination_file = os.path.join(category_folder, os.path.basename(image_name))\n",
    "    origin_file = os.path.join('./valid/all/', image_name)\n",
    "    \n",
    "    # Mover el archivo\n",
    "    shutil.move(origin_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(source_folder, destination_folder=None, grayscale=True, resize=True, resize_dimensions=(256, 256)):\n",
    "    # If destination folder is None, create a 'processed' folder within the source folder\n",
    "    if destination_folder is None:\n",
    "        # Create a 'processed' folder in the current directory if it doesn't exist\n",
    "        if not os.path.exists('./processed_dataset'):\n",
    "            os.makedirs('./processed_dataset')\n",
    "        destination_folder = './processed_dataset'\n",
    "    \n",
    "    # Ensure the destination directory exists\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "    # Walk through the source directory\n",
    "    for subdir, dirs, files in os.walk(source_folder):\n",
    "        for file in files:\n",
    "            # Check for image files\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                # Get the full path of the source image\n",
    "                source_path = os.path.join(subdir, file)\n",
    "\n",
    "                # Construct the relative path within the source directory and create a corresponding structure in the destination\n",
    "                relative_path = os.path.relpath(subdir, source_folder)\n",
    "                destination_subdir = os.path.join(destination_folder, relative_path)\n",
    "                os.makedirs(destination_subdir, exist_ok=True)\n",
    "\n",
    "                # Full path for the destination image\n",
    "                destination_path = os.path.join(destination_subdir, file)\n",
    "\n",
    "                # Read the image\n",
    "                image = cv2.imread(source_path)\n",
    "                if image is None:\n",
    "                    print(f\"Unable to read image: {source_path}\")\n",
    "                    continue\n",
    "\n",
    "                if grayscale:\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                if resize:\n",
    "                    image = cv2.resize(image, resize_dimensions)\n",
    "\n",
    "                cv2.imwrite(destination_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images('./Data/original/')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

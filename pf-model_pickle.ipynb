{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Fa91cgXnVwPo",
    "outputId": "2395a9a8-301a-4677-97d8-ba02830b82ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in ./venv/lib/python3.10/site-packages (1.1.7)\n",
      "Requirement already satisfied: tensorflow in ./venv/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: opencv-python in ./venv/lib/python3.10/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: datasets in ./venv/lib/python3.10/site-packages (2.14.6)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.10/site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: idna==2.10 in ./venv/lib/python3.10/site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.10/site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in ./venv/lib/python3.10/site-packages (from roboflow) (4.8.0.74)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.10/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in ./venv/lib/python3.10/site-packages (from roboflow) (2.0.7)\n",
      "Requirement already satisfied: certifi==2022.12.7 in ./venv/lib/python3.10/site-packages (from roboflow) (2022.12.7)\n",
      "Requirement already satisfied: chardet==4.0.0 in ./venv/lib/python3.10/site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.10/site-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in ./venv/lib/python3.10/site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./venv/lib/python3.10/site-packages (from roboflow) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil in ./venv/lib/python3.10/site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: cycler==0.10.0 in ./venv/lib/python3.10/site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in ./venv/lib/python3.10/site-packages (from roboflow) (10.1.0)\n",
      "Requirement already satisfied: requests-toolbelt in ./venv/lib/python3.10/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in ./venv/lib/python3.10/site-packages (from roboflow) (2.4.7)\n",
      "Requirement already satisfied: supervision in ./venv/lib/python3.10/site-packages (from roboflow) (0.16.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in ./venv/lib/python3.10/site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./venv/lib/python3.10/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.10/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./venv/lib/python3.10/site-packages (from tensorflow) (4.24.4)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./venv/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.10/site-packages (from tensorflow) (1.59.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./venv/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./venv/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.10/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in ./venv/lib/python3.10/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./venv/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: multiprocess in ./venv/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./venv/lib/python3.10/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (3.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./venv/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./venv/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib->roboflow) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.10/site-packages (from matplotlib->roboflow) (4.43.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./venv/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install roboflow tensorflow scikit-learn opencv-python transformers datasets torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 23:39:34.074073: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-25 23:39:34.101202: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-25 23:39:34.227836: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-25 23:39:34.227864: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-25 23:39:34.228796: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-25 23:39:34.287272: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-25 23:39:35.003004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/enrique/Documents/CamaraTest/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BeitFeatureExtractor, BeitForSemanticSegmentation\n",
    "from datasets import load_dataset\n",
    "from roboflow import Roboflow\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_proyect(path):\n",
    "    model = path.split('/')[-1]\n",
    "\n",
    "    if model == 'base.pkl':\n",
    "        rf = Roboflow(api_key='mjAeKepHoqRRVOJpbG3W')\n",
    "        project = rf.workspace(\"new-workspace-vrhvx\").project(\"distracted-driver-detection\")\n",
    "        dataset = project.version(3).download(\"tfrecord\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_body(image, save = False, class_index = 12):\n",
    "    global body_model\n",
    "\n",
    "    # Preprocesamiento de la imagen\n",
    "    image = cv2.resize(image, (640, 640))\n",
    "\n",
    "    # Inferencia\n",
    "    inputs = body_model[0](images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # Inferencia\n",
    "    output = body_model[1](**inputs)\n",
    "    output = output.logits\n",
    "    \n",
    "    logits_s = output.squeeze(0)\n",
    "\n",
    "    # Apply softmax to convert logits to probabilities\n",
    "    probs = F.softmax(logits_s, dim=0)\n",
    "\n",
    "    # Create a binary mask for the desired class\n",
    "    binary_mask = (probs[class_index, :, :] > 0.5).float()\n",
    "\n",
    "    # Convert image to tensor\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    # Resize the binary mask to match the image dimensions\n",
    "    binary_mask_resized = F.interpolate(binary_mask.unsqueeze(0).unsqueeze(0), size=image_tensor.shape[2:], mode='nearest').squeeze(0).squeeze(0)\n",
    "\n",
    "    # Create a dark tensor (all zeros)\n",
    "    dark_tensor = torch.zeros_like(image_tensor)\n",
    "\n",
    "    # Set the pixels outside the mask to dark\n",
    "    dark_tensor[0, :, :] = dark_tensor[0, :, :] * (1 - binary_mask_resized)\n",
    "\n",
    "    # Combine the image and binary mask\n",
    "    combined_image = image_tensor * binary_mask_resized + dark_tensor\n",
    "\n",
    "    # Convert the combined tensor back to a PIL Image\n",
    "    combined_image_pil = transforms.ToPILImage()(combined_image.squeeze())\n",
    "    if save:\n",
    "        combined_image_pil.save(f\"./frames/result_{class_index}.png\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_data(path):\n",
    "    model = path.split('/')[-1]\n",
    "\n",
    "    if model == 'body.pkl':\n",
    "        return load_dataset(\"hf-internal-testing/fixtures_ade20k\", split=\"test\")\n",
    "\n",
    "    if model == 'base.pkl':\n",
    "        label_map = {}\n",
    "        with open(\"./Distracted-Driver-Detection-3/train/driver_label_map.pbtxt\", \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            for i in range(0, len(lines), 5):  # Asumiendo que cada item ocupa 5 líneas\n",
    "                label = lines[i + 1].split('\"')[1]\n",
    "                label_id = int(lines[i + 2].split(\":\")[1].split(\",\")[0].strip())\n",
    "                label_map[label_id] = label\n",
    "\n",
    "        # Leer driver.tfrecord\n",
    "        raw_image_dataset = tf.data.TFRecordDataset('./Distracted-Driver-Detection-3/train/driver.tfrecord')\n",
    "\n",
    "        # Definir las características que quieres extraer\n",
    "        image_feature_description = {\n",
    "            'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "            'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/filename': tf.io.VarLenFeature(tf.string)\n",
    "        }\n",
    "\n",
    "        def _parse_image_function(example_proto):\n",
    "            return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "        parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "        for image_features in parsed_image_dataset:\n",
    "            image_raw = image_features['image/encoded'].numpy()\n",
    "            label = image_features['image/object/class/label'].values.numpy()[0]\n",
    "\n",
    "            # Convertir la imagen en formato raw a una matriz de numpy\n",
    "            image = cv2.imdecode(np.asarray(bytearray(image_raw), dtype=\"uint8\"), cv2.IMREAD_COLOR)\n",
    "            \n",
    "            # use body_model for image segmentation segm\n",
    "\n",
    "            image = detect_body(image)\n",
    "\n",
    "            X.append(image)\n",
    "            y.append(label)\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Convertir etiquetas a números\n",
    "        categories_dict = {category: index for index, category in enumerate(set(y))}\n",
    "        y = np.array([categories_dict[label] for label in y])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        return [X_train, X_test, y_train, y_test, categories_dict]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(path, data):\n",
    "    modelo = path.split('/')[-1]\n",
    "    if modelo == 'body.pkl':\n",
    "        feature_extractor = BeitFeatureExtractor.from_pretrained('microsoft/beit-base-finetuned-ade-640-640')\n",
    "        body = BeitForSemanticSegmentation.from_pretrained('microsoft/beit-base-finetuned-ade-640-640')\n",
    "        return [feature_extractor, body]\n",
    "\n",
    "    if modelo == 'base.pkl':\n",
    "        [X_train, X_test, y_train, y_test, categories_dict] = data\n",
    "        base = None\n",
    "\n",
    "        # Asegurarse de que todas las imágenes tienen la misma forma\n",
    "        if all(i.shape == X_train[0].shape for i in X_train):\n",
    "\n",
    "            # Normalizar datos\n",
    "            X_train = X_train / 255.0\n",
    "            X_test = X_test / 255.0\n",
    "\n",
    "            # Modelo CNN\n",
    "            base = Sequential()\n",
    "\n",
    "            # Capa 1\n",
    "            base.add(Conv2D(64, (3, 3), input_shape=X_train.shape[1:]))\n",
    "            base.add(Activation('relu'))\n",
    "            base.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            # Capa 2\n",
    "            base.add(Conv2D(64, (3, 3)))\n",
    "            base.add(Activation('relu'))\n",
    "            base.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            # Capa 3\n",
    "            base.add(Flatten())\n",
    "            base.add(Dense(64))\n",
    "            base.add(Activation('relu'))\n",
    "\n",
    "            # Capa de salida\n",
    "            base.add(Dense(len(categories_dict)))\n",
    "            base.add(Activation('softmax'))\n",
    "\n",
    "            # Compilación del modelo\n",
    "            base.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Entrenamiento\n",
    "            base.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "        else:\n",
    "            print(\"No todas las imágenes tienen la misma forma. Asegúrate de preprocesarlas para que tengan la misma forma antes de alimentarlas al modelo.\")\n",
    "        \n",
    "        return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XVR7-etO7iuT"
   },
   "outputs": [],
   "source": [
    "def init_model(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as file:\n",
    "            modelo = pickle.load(file)\n",
    "            print(f\"Modelo {path} cargado correctamente.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No se encontró el archivo {path}.\")\n",
    "        print(\"Descargando proyecto...\")\n",
    "        proyect = download_proyect(path)\n",
    "\n",
    "        print(\"Preparando datos...\")\n",
    "        data = prepare_model_data(path)\n",
    "\n",
    "        print(\"Entrenando modelo...\")\n",
    "        modelo = train_model(path, data)\n",
    "\n",
    "        print(\"Guardando modelo...\")\n",
    "        with open(path, 'wb') as file:\n",
    "            pickle.dump(modelo, file)\n",
    "            print(\"Modelo guardado correctamente.\")\n",
    "    \n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    global body_model, base_model\n",
    "\n",
    "    body_model = init_model(\"./models/body.pkl\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    base_model = init_model(\"./models/base.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo ./models/body.pkl cargado correctamente.\n",
      "\n",
      "No se encontró el archivo ./models/base.pkl.\n",
      "Descargando proyecto...\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Distracted-Driver-Detection-3 to tfrecord:: 100%|██████████| 147719/147719 [00:04<00:00, 32969.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Distracted-Driver-Detection-3 in tfrecord:: 100%|██████████| 11/11 [00:00<00:00, 47.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando datos...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "load_models()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
